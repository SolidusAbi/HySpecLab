{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "project_dir = os.path.join(os.getcwd(),'../..')\n",
    "if project_dir not in sys.path:\n",
    "    sys.path.append(project_dir)\n",
    "\n",
    "hyspeclab_dir = os.path.join(project_dir, 'HySpecLab')\n",
    "if hyspeclab_dir not in sys.path:\n",
    "    sys.path.append(hyspeclab_dir)\n",
    "\n",
    "ipdl_dir = os.path.join(project_dir, 'modules/IPDL')\n",
    "if ipdl_dir not in sys.path:\n",
    "    sys.path.append(ipdl_dir)\n",
    "\n",
    "sparse_dir = os.path.join(project_dir, 'modules/Sparse')\n",
    "if sparse_dir not in sys.path:\n",
    "    sys.path.append(sparse_dir)\n",
    "\n",
    "import config\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from matplotlib import pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HySpecLab.dataset import DermaDataset\n",
    "\n",
    "train_dir = ['train', 'validation']\n",
    "dataset_dir = list(map(lambda x: os.path.join(config.DERMA_DATASET_DIR, x), train_dir))\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch\n",
    "\n",
    "class DermaDatasetTorch(Dataset):\n",
    "    def __init__(self, dataset_dir):\n",
    "        super(DermaDatasetTorch, self).__init__()\n",
    "        dataset = DermaDataset(dataset_dir)\n",
    "        self.x, self.y = dataset.get(dataframe=False)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.x[idx], dtype=torch.float32), torch.tensor(self.y[idx])\n",
    "\n",
    "\n",
    "dataset = DermaDatasetTorch(dataset_dir)\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "loader = DataLoader(dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Sparse import KWinners\n",
    "\n",
    "model = nn.Sequential(*[\n",
    "    nn.Conv1d(116, 116, 1, bias=False),\n",
    "    nn.Flatten(start_dim=1),\n",
    "    KWinners(116, 25), # K Most relevant bands\n",
    "    nn.BatchNorm1d(116),\n",
    "    nn.Linear(116, 64),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.BatchNorm1d(64),\n",
    "    nn.Linear(64, 24),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.BatchNorm1d(24),\n",
    "    nn.Linear(24, 2),\n",
    "    nn.Softmax(dim=1)\n",
    "])\n",
    "\n",
    "for l in model.modules():\n",
    "    if isinstance(l, nn.Conv1d):\n",
    "        nn.init.kaiming_normal_(l.weight, mode='fan_out', nonlinearity='relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from torch.nn.functional import one_hot\n",
    "\n",
    "n_epoch = 20\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-6)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "epoch_iterator = tqdm(\n",
    "        range(n_epoch),\n",
    "        leave=True,\n",
    "        unit=\"epoch\",\n",
    "        postfix={\"tls\": \"%.4f\" % 1},\n",
    "    )\n",
    "model.train()\n",
    "loss_value = []\n",
    "for epoch in epoch_iterator:\n",
    "    for input, target in loader:\n",
    "        input = input.to(device)\n",
    "        target = one_hot(target).float().to(device)\n",
    "\n",
    "        out = model(input[:,:,None])\n",
    "        loss = criterion(out, target)\n",
    "        loss_value.append(loss.item())\n",
    "\n",
    "        # epoch_iterator.set_postfix(tls=\"%.4f\" % np.mean(loss.detach().item()))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    epoch_iterator.set_postfix(tls=\"%.4f\" % np.mean(loss_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "kwinner_out = model[0:3](input[:,:,None])[0].detach().cpu()\n",
    "\n",
    "selected = input.clone()[0].detach().cpu()\n",
    "selected[kwinner_out == 0] = 0\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(16,6))\n",
    "fig.suptitle('Selected features')\n",
    "ax[0].plot(selected)\n",
    "ax[0].set_title('Original values')\n",
    "ax[1].plot(kwinner_out.detach().cpu())\n",
    "ax[1].set_title('Layer output')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "15b37510c40f952771730cdce6ed2555d8094a99b7d6886f5b16bebe3e0bdfae"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('HySpecLab': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
