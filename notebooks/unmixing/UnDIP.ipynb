{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "project_dir = os.path.join(os.getcwd(),'../..')\n",
    "if project_dir not in sys.path:\n",
    "    sys.path.append(project_dir)\n",
    "\n",
    "hyspeclab_dir = os.path.join(project_dir, 'HySpecLab')\n",
    "if hyspeclab_dir not in sys.path:\n",
    "    sys.path.append(hyspeclab_dir)\n",
    "\n",
    "ipdl_dir = os.path.join(project_dir, 'modules/IPDL')\n",
    "if ipdl_dir not in sys.path:\n",
    "    sys.path.append(ipdl_dir)\n",
    "\n",
    "svdd_dir = os.path.join(project_dir, 'modules/SVDD')\n",
    "if svdd_dir not in sys.path:\n",
    "    sys.path.append(svdd_dir)\n",
    "\n",
    "from matplotlib import pyplot as plt \n",
    "import numpy as np\n",
    "import torch\n",
    "import config\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "\n",
    "dataset_path = os.path.join(config.DERMA_DATASET_DIR, 'train/')\n",
    "subjects = os.listdir(dataset_path)[::12]\n",
    "\n",
    "subject_data = []\n",
    "subject_target = []\n",
    "for i in subjects:\n",
    "    mat = loadmat(os.path.join(dataset_path, i))\n",
    "    subject_data.append(mat['preProcessedImage'].astype(np.float64)[np.newaxis,:])\n",
    "\n",
    "    mat_y = mat['groundTruthMap']\n",
    "    y = np.zeros(mat_y.shape,  dtype=int)\n",
    "    # benign_idx = np.where(np.logical_and(mat_y>200, mat_y<400))\n",
    "    malignant_idx = np.where(np.logical_and(mat_y>=400, mat_y<500))\n",
    "    # y[benign_idx] = 2\n",
    "    y[malignant_idx] = 1\n",
    "    subject_target.append(y[np.newaxis,:])\n",
    "\n",
    "subject_data = np.concatenate(subject_data)\n",
    "subject_target = np.concatenate(subject_target)\n",
    "mean_value = subject_data[np.logical_not(np.isnan(subject_data))].mean()\n",
    "subject_data = np.nan_to_num(subject_data, nan=mean_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Endmember Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_endmembers = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NFINDR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pysptools import eea\n",
    "\n",
    "ee = eea.NFINDR()\n",
    "U = torch.tensor(ee.extract(subject_data.reshape(subject_data.shape[0]*subject_data.shape[1], subject_data.shape[2], -1), \n",
    "                            n_endmembers, \n",
    "                            maxit=1024, \n",
    "                            normalize=False,\n",
    "                            ATGP_init=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HySpecLab.eea import VCA\n",
    "\n",
    "eea = VCA(n_endmembers)\n",
    "data = subject_data.reshape(subject_data.shape[0]*subject_data.shape[1]*subject_data.shape[2], subject_data.shape[3])\n",
    "eea.fit(data)\n",
    "U = torch.tensor(eea.endmembers())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HySpecLab.eea import SVDD\n",
    "\n",
    "eea = SVDD(sigma=.1, d=2, n_samples=1200, C=100)\n",
    "X = subject_data.reshape(subject_data.shape[0]*subject_data.shape[1]*subject_data.shape[2], -1)\n",
    "y = subject_target.reshape(subject_target.shape[0]*subject_target.shape[1] * subject_target.shape[2], -1)\n",
    "eea.fit(X, y)\n",
    "U = torch.tensor(eea.endmembers())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt \n",
    "plt.plot(U.T)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import Compose, ToTensor, Resize, InterpolationMode, Normalize\n",
    "\n",
    "transform = Compose([\n",
    "    ToTensor(),\n",
    "    Resize((64,64), InterpolationMode.NEAREST),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset \n",
    "from torchvision import transforms as torchTransforms\n",
    "\n",
    "class AuxDataset(Dataset):\n",
    "    def __init__(self, data, transform=torchTransforms.Compose([torchTransforms.ToTensor()])):\n",
    "        super(AuxDataset, self).__init__()\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.transform(self.data[idx])\n",
    "\n",
    "train_set = AuxDataset(subject_data, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "loader = DataLoader(train_set, batch_size=32, shuffle=False)\n",
    "X_tensor = next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HySpecLab.unmixing import get_noise, NOISE_TYPE\n",
    "noisy_input = get_noise(X_tensor.shape[1:], batch_size = X_tensor.shape[0], noise_type=NOISE_TYPE.uniform)\n",
    "\n",
    "U_tensor = torch.unsqueeze(U.T, dim=0).float()\n",
    "\n",
    "print('Z shape: {}'.format(noisy_input.shape))\n",
    "print('HyperCube shape: {}'.format(X_tensor.shape))\n",
    "print('Endmember shape: {}'.format(U_tensor.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HySpecLab.unmixing import UnDIP\n",
    "\n",
    "n_bands = X_tensor.shape[1]\n",
    "n_endmembers = U_tensor.shape[-1]\n",
    "\n",
    "dims = [n_bands, 256]\n",
    "skip_connection = [6]\n",
    "out_channels = 64\n",
    "\n",
    "model = UnDIP(n_endmembers, out_channels, dims, skip_connection, dropout=False, batch_norm=True, activation_func=nn.ReLU())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision.utils import make_grid\n",
    "from HySpecLab.utils import fig_to_image\n",
    "from HySpecLab.unmixing.utils import restoration\n",
    "\n",
    "batch_size = X_tensor.shape[0]\n",
    "n_bands = X_tensor.shape[1]\n",
    "w, h = X_tensor.shape[2:]\n",
    "\n",
    "n_epoch = 15000\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-6)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "epoch_iterator = tqdm(\n",
    "        range(n_epoch),\n",
    "        leave=True,\n",
    "        unit=\"epoch\",\n",
    "        postfix={\"tls\": \"%.4f\" % 1},\n",
    "    )\n",
    "\n",
    "tb_writer = SummaryWriter('logs/test')\n",
    "\n",
    "#Endmember signal image\n",
    "fig, ax = plt.subplots(1,1, figsize=(16,9))\n",
    "\n",
    "labels = list(map(lambda x: 'Endmember {}'.format(x), range(len(U))))\n",
    "ax.plot(U.T, label=labels)\n",
    "ax.set_ylabel('Reflectance')\n",
    "\n",
    "image = ToTensor()(fig_to_image(fig)).unsqueeze(0)\n",
    "tb_writer.add_image('Endmembers', image, dataformats='NCHW')\n",
    "\n",
    "\n",
    "# Target Image\n",
    "show_band_idx = np.linspace(0, X_tensor.shape[1]-1, num=16, dtype=np.int64)\n",
    "for i in range(4):\n",
    "    target_imgs = torch.unsqueeze(X_tensor[i, show_band_idx], dim=1)\n",
    "    img_grid = make_grid(target_imgs)\n",
    "    tb_writer.add_image('Target/{}'.format(i), img_grid, 0)\n",
    "\n",
    "\n",
    "noisy_input = noisy_input.to(device)\n",
    "\n",
    "for epoch in epoch_iterator:\n",
    "    abundance = model(noisy_input)\n",
    "\n",
    "    output = restoration(U_tensor.to(device), abundance)\n",
    "\n",
    "    if epoch % 100 == 0: # Cada 100 epoch\n",
    "        for i in range(4):\n",
    "            rest_imgs = torch.unsqueeze(output[i, show_band_idx], dim=1)\n",
    "            img_grid = make_grid(rest_imgs)\n",
    "            tb_writer.add_image('Output/{}'.format(i), img_grid, epoch)\n",
    "\n",
    "            abundance_imgs = torch.unsqueeze(abundance[i], dim=1)\n",
    "            img_grid = make_grid(abundance_imgs)\n",
    "            tb_writer.add_image('Abundance/{}'.format(i), img_grid, epoch)\n",
    "\n",
    "    batch_loss = criterion(output, X_tensor.float().to(device))\n",
    "\n",
    "    epoch_iterator.set_postfix(tls=\"%.4f\" % np.mean(batch_loss.detach().item()))\n",
    "    tb_writer.add_scalar('Loss', batch_loss.detach().item(), epoch)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    batch_loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import ToPILImage\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "A = model(noisy_input).cpu().detach()\n",
    "fig, ax = plt.subplots(4,4, figsize=(12,9))\n",
    "for i in range(len(A[0])):\n",
    "    if i >= 4:\n",
    "        break\n",
    "    \n",
    "    for j in range(len(A[1])):\n",
    "        ax[i, j].imshow(A[i,j])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "15b37510c40f952771730cdce6ed2555d8094a99b7d6886f5b16bebe3e0bdfae"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('HySpecLab': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
