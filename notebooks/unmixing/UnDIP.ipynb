{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "project_dir = os.path.join(os.getcwd(),'../..')\n",
    "if project_dir not in sys.path:\n",
    "    sys.path.append(project_dir)\n",
    "\n",
    "hyspeclab_dir = os.path.join(project_dir, 'HySpecLab')\n",
    "if hyspeclab_dir not in sys.path:\n",
    "    sys.path.append(hyspeclab_dir)\n",
    "\n",
    "ipdl_dir = os.path.join(project_dir, 'modules/IPDL')\n",
    "if ipdl_dir not in sys.path:\n",
    "    sys.path.append(ipdl_dir)\n",
    "\n",
    "ae_dir = os.path.join(project_dir, 'modules/AutoEncoder')\n",
    "if ae_dir not in sys.path:\n",
    "    sys.path.append(ae_dir)\n",
    "\n",
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "from collections import OrderedDict\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels) -> None:\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.encode = nn.Sequential(OrderedDict([\n",
    "                ('conv_0', nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1)), \n",
    "                ('act_0', nn.Sigmoid()), \n",
    "                ('pooling', nn.MaxPool2d(kernel_size=3, stride=2, padding=1)), \n",
    "                ('conv_1', nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)), \n",
    "                ('act_1', nn.Sigmoid())\n",
    "            ])\n",
    "        )\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        return self.encode(x)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels) -> None:\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.decode = nn.Sequential(OrderedDict([\n",
    "                ('upsampling', nn.Upsample(scale_factor=2, mode='nearest')),\n",
    "                ('conv_0', nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1)),\n",
    "                ('act_0', nn.Sigmoid()),\n",
    "                ('conv_1', nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)),\n",
    "                ('act_1', nn.Sigmoid())\n",
    "            ])\n",
    "        )\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        return self.decode(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "class Level(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, skip_channels = 0, deeper = None):\n",
    "        super(Level, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels if deeper else in_channels\n",
    "\n",
    "        if skip_channels:\n",
    "            self.skip_ = nn.Sequential(OrderedDict([\n",
    "                    ('conv', nn.Conv2d(in_channels, skip_channels, kernel_size=1, stride=1)),\n",
    "                    ('activation', nn.Sigmoid())\n",
    "                ])\n",
    "            )\n",
    "\n",
    "        if not deeper:\n",
    "            self.f = Encoder(in_channels, out_channels)\n",
    "            self.decoder = Decoder(out_channels + skip_channels, in_channels)\n",
    "        else:\n",
    "            if not isinstance(deeper, Level):\n",
    "                raise ValueError('Meh!')\n",
    "            \n",
    "            self.f = nn.Sequential(\n",
    "                Encoder(in_channels, deeper.in_channels),\n",
    "                deeper\n",
    "            )\n",
    "\n",
    "            print(out_channels)\n",
    "            self.decoder = Decoder(deeper.out_channels + skip_channels, out_channels)\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        x = torch.cat([self.skip_(x), self.decoder.decode[0](self.f(x))], dim=1) if hasattr(self, 'skip_') else self.f(x)\n",
    "        return self.decoder.decode[1:](x) if hasattr(self, 'skip_') else self.decoder(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnDIP(nn.Module):\n",
    "    ''' \n",
    "        HyperSpectral Unmixing using Deep Image Prior (UnDIP)\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "            in_channels\n",
    "            out_channels\n",
    "            skip_channels\n",
    "\n",
    "        Reference\n",
    "        ---------\n",
    "            [1] UnDIP: Hyperspectral Unmixing Using Deep Image Prior (10.1109/TGRS.2021.3067802)\n",
    "    '''\n",
    "    def __init__(self, in_channels, out_channels, skip_channels, n_endmembers=4) -> None:\n",
    "        ''' \n",
    "        \n",
    "        '''\n",
    "        super(UnDIP, self).__init__()\n",
    "        if not(isinstance(in_channels, list)) or not(isinstance(out_channels, list)) or not(isinstance(skip_channels, list)):\n",
    "            raise ValueError('Parameters must be list')\n",
    "\n",
    "        if len(in_channels) != len(out_channels) != len(skip_channels):\n",
    "            raise ValueError('The parameters must contain the samme number of elements')\n",
    "        \n",
    "        out_channels_inv = out_channels[::-1]\n",
    "        skip_channels_inv = skip_channels[::-1]\n",
    "        for idx, in_channel in enumerate(in_channels[::-1]):\n",
    "            self.prior = Level(in_channel, out_channels_inv[idx], skip_channels=skip_channels_inv[idx], deeper=(self.prior if hasattr(self, 'prior') else None) )\n",
    "\n",
    "        self.unmix = nn.Sequential(OrderedDict([\n",
    "            ('conv_0', nn.Conv2d(out_channels[0], out_channels[0], kernel_size=3, stride=1, padding=1)),\n",
    "            ('act_0', nn.LeakyReLU(negative_slope=.1)),\n",
    "            ('bn_0', nn.BatchNorm2d(out_channels[0])),\n",
    "            ('ee_conv', nn.Conv2d(out_channels[0], n_endmembers, kernel_size=3, stride=1, padding=1)),\n",
    "            ('ee_act', nn.Softmax(dim=1)),\n",
    "        ]))\n",
    "\n",
    "    def forward(self, x : Tensor) -> Tensor:\n",
    "        x = self.prior(x)\n",
    "        return self.unmix(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "n_bands = 116\n",
    "n_endmembers = 6\n",
    "\n",
    "in_channels = [n_bands, 12]\n",
    "out_channels = [10, 4]\n",
    "skip_channels = [0, 0]\n",
    "\n",
    "model = UnDIP(in_channels, out_channels, skip_channels, n_endmembers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = torch.rand((6, n_bands, 16, 16))\n",
    "result = model(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 116])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endmembers = torch.rand(1, n_endmembers, n_bands)\n",
    "endmembers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 116, 256])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(torch.transpose(endmembers, 2, 1), result.flatten(start_dim=2)).shape\n",
    "# result * endmembers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[0].flatten(start_dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.transpose(endmembers, 2, 1) == endmembers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.transpose(endmembers, 2, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = result[0]\n",
    "test[0, 10, 10] + test[1, 10, 10] + test[2, 10, 10] + test[3, 10, 10] + test[4, 10, 10] + test[5, 10, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.Softmax(dim=1)\n",
    "input = torch.randn(1, 3, 4, 4)\n",
    "output = m(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand((1,3,128,128))\n",
    "test3(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hasattr(test, 'skip_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2.f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "15b37510c40f952771730cdce6ed2555d8094a99b7d6886f5b16bebe3e0bdfae"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('HySpecLab': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
