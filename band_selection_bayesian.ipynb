{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os, sys\n",
    "project_dir = os.getcwd()\n",
    "if project_dir not in sys.path:\n",
    "    sys.path.append(project_dir)\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score, RepeatedStratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from skopt.space import Integer\n",
    "from skopt.space import Real\n",
    "from skopt.space import Categorical\n",
    "from skopt.utils import use_named_args\n",
    "from skopt import gp_minimize"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from dataset import DermaDataset\n",
    "\n",
    "dataset_root_dir = \"/home/abian/Workspace/Dataset/IUMA/dataCubes/\"\n",
    "train_dir = ['train', 'validation']\n",
    "dataset_dir = list(map(lambda x: os.path.join(dataset_root_dir, x), train_dir))\n",
    "\n",
    "dataset = DermaDataset(dataset_dir)\n",
    "x, y = dataset.get()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset balancing\n",
    "**https://imbalanced-learn.org/stable/under_sampling.html**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler, NearMiss\n",
    "\n",
    "# Randomly selecting a subset of data for the targeted classes:\n",
    "# rus = RandomUnderSampler(random_state=123)\n",
    "# x, y = rus.fit_resample(x, y)\n",
    "\n",
    "# Let positive samples be the samples belonging to the targeted class to be under-sampled. \n",
    "# Negative sample refers to the samples from the minority class.\n",
    "# Select the positive samples for which the average distance to the N closest samples of the negative class is the smallest\n",
    "nm1 = NearMiss(version=1)\n",
    "x, y = nm1.fit_resample(x, y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Feature Reduction\n",
    "\n",
    "Due to a computational limitation, it is now only possible to apply the selection of features by Bayesian optimization up to 64 features. This step is used in order to reduce the number of features based on Tree-based feature importance score."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# clf = ExtraTreesClassifier(n_estimators=150)\n",
    "clf = RandomForestClassifier(random_state=123)\n",
    "clf_params={'n_estimators':[50, 150, 500, 1000]}\n",
    "\n",
    "fs_clf = GridSearchCV(clf, clf_params, cv=10,iid=False, n_jobs=-1)\n",
    "fs_clf.fit(x,y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Best estimator: {}\".format(fs_clf.best_estimator_))\n",
    "fi = fs_clf.best_estimator_.feature_importances_"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "threshold = 0.007 #Empirical value\n",
    "fs_model = SelectFromModel(fs_clf.best_estimator_, threshold=threshold, prefit=True)\n",
    "X_new = fs_model.transform(x)\n",
    "\n",
    "print(\"Features selected: {}\".format(np.where(fs_clf.best_estimator_.feature_importances_ > threshold)[0]))\n",
    "print(\"X shape: {}\".format(X_new.shape))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Parameters optimization"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from feature_selection import FeatureSelection, FeatureEquidistantSelection\n",
    "from sklearn.pipeline import Pipeline\n",
    "from skopt import BayesSearchCV"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "search_space = list()\n",
    "# search_space.append(Integer(1, float(2**(116)-1), 'log-uniform', name='transform__selected_features'))\n",
    "search_space.append(Integer(0, 2**(64)-1, 'uniform', name='transform__selected_features', dtype=np.uint64))\n",
    "search_space.append(Real(1e-6, 100.0, 'log-uniform', name='svc__C'))\n",
    "search_space.append(Categorical(['linear', 'poly', 'rbf', 'sigmoid'], name='svc__kernel'))\n",
    "search_space.append(Integer(1, 5, name='svc__degree'))\n",
    "search_space.append(Real(1e-6, 100.0, 'log-uniform', name='svc__gamma'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# define the function used to evaluate a given configuration\n",
    "@use_named_args(search_space) # https://scikit-optimize.github.io/stable/modules/generated/skopt.utils.use_named_args.html\n",
    "def evaluate_model(**params):\n",
    "\t# configure the model with specific hyperparameters\n",
    "\tmodel = Pipeline([(\"transform\", FeatureSelection()), ('svc', SVC())])\n",
    "\tmodel.set_params(**params)\n",
    "\t# define test harness\n",
    "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=123)\n",
    "\t# calculate 5-fold cross validation\n",
    "\tresult = cross_val_score(model, X_new, y, cv=cv, n_jobs=-1, scoring='accuracy')\n",
    "\t# calculate the mean of the scores\n",
    "\testimate = np.mean(result)\n",
    "\t\n",
    "\t# TODO, Comprobar penalizaci√≥n por bandas!\n",
    "\t# Acc_Penalized = None\n",
    "\t# if model['transform'].selected_features:\n",
    "\t# \tfeature_idx = model['transform'].getIndex()\n",
    "\t# \tAcc_Penalized = 1 - (estimate / (1 + (feature_idx.sum()/model['transform'].n_features)))\n",
    "\n",
    "\t# convert from a maximizing score to a minimizing score\n",
    "\treturn 1.0 - estimate\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from skopt.callbacks import CheckpointSaver\n",
    "from datetime import datetime\n",
    "\n",
    "exp_id = f'{datetime.now().timestamp()}'.split('.')[0]\n",
    "checkpoint_saver = CheckpointSaver(\"./checkpoints/{}.pkl\".format(exp_id), compress=9) # keyword arguments will be passed to `skopt.dump`\n",
    "\n",
    "result = gp_minimize(evaluate_model, search_space, callback=[checkpoint_saver], random_state=123)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# summarizing finding:\n",
    "print('Best Accuracy: %.3f' % (1.0 - result.fun))\n",
    "print('Best Parameters: %s' % (result.x))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Old"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from feature_selection import FeatureSelection, FeatureEquidistantSelection\n",
    "from sklearn.pipeline import Pipeline\n",
    "from skopt import BayesSearchCV\n",
    "\n",
    "\n",
    "# pipe = Pipeline([(\"transform\", FeatureEquidistantSelection()), ('svc', SVC())])\n",
    "pipe = Pipeline([(\"transform\", FeatureSelection()), ('svc', SVC())])\n",
    "\n",
    "params = dict()\n",
    "n_features = x.shape[1]\n",
    "# params['transform__n_features_to_select'] = (8, 34, 'uniform')\n",
    "params['transform__selected_features'] = Integer(1, float(2**(116)-1), 'log-uniform')\n",
    "params['svc__C'] = (1e-6, 100.0, 'log-uniform')\n",
    "params['svc__gamma'] = (1e-6, 100.0, 'log-uniform')\n",
    "params['svc__degree'] = (1,5)\n",
    "params['svc__kernel'] = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "\n",
    "# define evaluation\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=123)\n",
    "# define the search\n",
    "search = BayesSearchCV(estimator=pipe, search_spaces=params, n_jobs=-1, cv=cv)\n",
    "# perform the search\n",
    "search.fit(x, y)\n",
    "# report the best result\n",
    "print(search.best_score_)\n",
    "print(search.best_params_)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Test!!\n",
    "\n",
    "# url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/ionosphere.csv'\n",
    "# df = pd.read_csv(url, header=None)\n",
    "# data = df.values\n",
    "\n",
    "# x, y = data[:, :-1], data[:, -1]\n",
    "# print(np.unique(y))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(x.shape)\n",
    "print(y.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from feature_selection import FeatureSelection, FeatureEquidistantSelection\n",
    "from sklearn.pipeline import Pipeline\n",
    "from skopt import BayesSearchCV\n",
    "\n",
    "\n",
    "# pipe = Pipeline([(\"transform\", FeatureEquidistantSelection()), ('svc', SVC())])\n",
    "pipe = Pipeline([(\"transform\", FeatureSelection()), ('svc', SVC())])\n",
    "\n",
    "params = dict()\n",
    "n_features = x.shape[1]\n",
    "# params['transform__n_features_to_select'] = (8, 34, 'uniform')\n",
    "params['transform__selected_features'] = Integer(1, float(2**(116)-1), 'log-uniform')\n",
    "params['svc__C'] = (1e-6, 100.0, 'log-uniform')\n",
    "params['svc__gamma'] = (1e-6, 100.0, 'log-uniform')\n",
    "params['svc__degree'] = (1,5)\n",
    "params['svc__kernel'] = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "\n",
    "# define evaluation\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# define the search\n",
    "search = BayesSearchCV(estimator=pipe, search_spaces=params, n_jobs=-1, cv=cv)\n",
    "# perform the search\n",
    "search.fit(x, y)\n",
    "# report the best result\n",
    "print(search.best_score_)\n",
    "print(search.best_params_)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "type(2**(116)-1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "np.log10(float(2**(116)-1)) / 10"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "values = 9642075140\n",
    "feature_idx = format(values, \"b\").zfill(34)\n",
    "feature_idx = np.array(list(map(int, feature_idx)), dtype=np.bool_)\n",
    "feature_idx"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
    "y = np.array([0, 0, 1, 1])\n",
    "rskf = RepeatedStratifiedKFold(n_splits=2, n_repeats=2, random_state=36851234)\n",
    "for train_index, test_index in rskf.split(X, y):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('HySpecLab': conda)"
  },
  "interpreter": {
   "hash": "ad5935529b3b777884ef70b3275d7b140d952d98f99a9f9dfce92ade9f76e179"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}