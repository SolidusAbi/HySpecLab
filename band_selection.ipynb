{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os, sys\n",
    "import os, sys\n",
    "project_dir = os.getcwd()\n",
    "if project_dir not in sys.path:\n",
    "    sys.path.append(project_dir)\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from matplotlib import pyplot as plt\n",
    "from spectral.algorithms import spectral_angles\n",
    "from dataset import Dataset"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "dataset_dir = '/home/abian/Data/Dataset/IUMA/DermaDatabase/'\n",
    "dataset = Dataset(dataset_dir)\n",
    "x, y = dataset.get()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "classes = np.unique(y)\n",
    "for i in range(len(classes)):\n",
    "    idx = np.where(y==classes[i])\n",
    "    n_samples = y[idx].size\n",
    "    print('Class {}: {} samples'.format(classes[i], n_samples))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Class b'a': 13084 samples\n",
      "Class b'b': 3051 samples\n",
      "Class b'c': 1083 samples\n",
      "Class b'd': 63 samples\n",
      "Class b'e': 283 samples\n",
      "Class b'f': 569 samples\n",
      "Class b'g': 274 samples\n",
      "Class b'h': 98 samples\n",
      "Class b'i': 582 samples\n",
      "Class b'j': 1378 samples\n",
      "Class b'k': 90 samples\n",
      "Class b'l': 3885 samples\n",
      "Class b'm': 601 samples\n",
      "Class b'n': 3775 samples\n",
      "Class b'o': 73 samples\n",
      "Class b'p': 132 samples\n",
      "Class b'q': 24 samples\n",
      "Class b'r': 244 samples\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "dataset.label_map"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'a': 100,\n",
       " 'b': 200,\n",
       " 'c': 201,\n",
       " 'd': 202,\n",
       " 'e': 203,\n",
       " 'f': 204,\n",
       " 'g': 207,\n",
       " 'h': 209,\n",
       " 'i': 210,\n",
       " 'j': 300,\n",
       " 'k': 301,\n",
       " 'l': 400,\n",
       " 'm': 401,\n",
       " 'n': 402,\n",
       " 'o': 403,\n",
       " 'p': 404,\n",
       " 'q': 406,\n",
       " 'r': 407}"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "## Calibration \n",
    "\n",
    "$\\begin{align}\n",
    "    C_i = 100 * \\frac{R_i - D_r}{W_r - D_r}\n",
    "\\end{align}$\n",
    "\n",
    "where $C_i$ is the calibrated image, $R_i$ note raw image and the $W_r$ and $D_r$ represents the white and dark reference image, respectively.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# W_r y D_r es una imagen\n",
    "def calibrate(img, w_r, d_r):\n",
    "    if not(w_r.shape == d_r.shape == img.shape):\n",
    "        assert('Dimensionality error')\n",
    "    \n",
    "    return 100  * (img - d_r) / (w_r - d_r)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Normalize data\n",
    "$\\begin{align}\n",
    "    P'_i = \\frac{P_i - P_{min}}{P_{max} - P_{min}}\n",
    "\\end{align}$\n",
    "\n",
    "where $P'_i$ is the normalized pixel value, $P_i$ the reflectance of the pixel, $P_{min}$ and $P_{max}$ is the minimum and maximum reflectance value, respectively."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def normalize(img):\n",
    "    return (img - img.min()) / (img.max() - img.min())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Sampling Interval Analysis\n",
    "\n",
    "Selected band equidistant...\n",
    "\n",
    "$\\begin{align}\n",
    "    Sampling Interval (nm) = \\frac{\\lambda_{max} - \\lambda_{min}}{N_{\\lambda}}\n",
    "\\end{align}$\n",
    "\n",
    "where $\\lambda_{max} - \\lambda_{min}$ is the difference between the mamum and minimum wavelength and $N_{\\lambda}$ is the number of band captured by the sensor."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def sampling_interval(lambda_min, lambda_max, n_spectral_bands):\n",
    "    '''\n",
    "        Param:\n",
    "        -----\n",
    "            lambda_min (int): minimum wavelenght\n",
    "            lambda_max (int): maximum wavelenght\n",
    "            n_spectral_bands (int): number of spectral bands captured by the sensor\n",
    "    '''\n",
    "    return (lambda_max - lambda_min) / n_spectral_bands"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset reduction\n",
    "\n",
    "**Spectral Angle Mapper**\n",
    "\n",
    "$[\\alpha = cos^{-1}\\left ( \\frac{\\sum_{i = 1}^{nb} t_{i} r_{i}}{(\\sum_{i = 1}^{nb} t_{i}^2)^{\\frac{1}{2}} (\\sum_{i = 1}^{nb} r_{i}^2)^{\\frac{1}{2}}} \\right )]$\n",
    "\n",
    "where\n",
    "\n",
    "* $\\alpha$ = spectral angle between the standard and the spectral curve of the pixel\n",
    "* $nb$ = number of spectral channels\n",
    "* $t$ = vector of spectral response of the standard\n",
    "* $r$ = the spectral response vector of the analyzed pixel"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "from spectral.algorithms import spectral_angles\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def spectral_angles_pixel(x, ref):\n",
    "    '''\n",
    "        For pixel input, the original function is prepare for image\n",
    "    '''\n",
    "    return spectral_angles(x[np.newaxis,:], ref)[0]\n",
    "\n",
    "def get_most_relevant_samples(x, centroid, n_samples_per_centroid=10):\n",
    "    '''\n",
    "        Paper: Most Relevant Spectral Bands Identification for Brain\n",
    "        Cancer Detection Using Hyperspectral Imaging    \n",
    "    '''\n",
    "    if len(x.shape) != 2:\n",
    "        assert 'X shape error!'\n",
    "    \n",
    "    output = None\n",
    "    result = spectral_angles_pixel(x, centroid)\n",
    "    for i in range(len(centroid)):       \n",
    "        ind = np.argpartition(result[i], -n_samples_per_centroid)[-n_samples_per_centroid:]\n",
    "        if i == 0:\n",
    "            output = x[ind]\n",
    "        else:\n",
    "            output = np.concatenate([output, x[ind]], axis=0)\n",
    "\n",
    "    return output\n",
    "\n",
    "def dataset_reduction(x, y, n_centroid_per_class=100, random_state=123):\n",
    "    class_label = np.unique(y)\n",
    "    final_x = None\n",
    "    final_y = None\n",
    "    for i in range(len(class_label)):\n",
    "        idx = np.where(y==class_label[i])\n",
    "        _x = x[idx]\n",
    "        if len(idx[0]) > 1000:\n",
    "            kmeans = KMeans(n_clusters=n_centroid_per_class, random_state=random_state).fit(_x)\n",
    "            centroid = kmeans.cluster_centers_\n",
    "            _x = get_most_relevant_samples(_x, centroid)\n",
    "\n",
    "        if i == 0:\n",
    "            final_x = _x\n",
    "            final_y = np.full((_x.shape[0],), class_label[i])\n",
    "        else:\n",
    "            final_x = np.concatenate([final_x, _x], axis=0)\n",
    "            final_y = np.concatenate([final_y, np.full((_x.shape[0],), class_label[i])], axis=0)\n",
    "    \n",
    "    return final_x, final_y"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "x_red, y_red = dataset_reduction(x, y)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "x_red.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(9033, 116)"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "y_red.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(9033,)"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "2**()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Optimization\n",
    "\n",
    "## Steps involved in HyperOptimization using Scikit-Optimizer\n",
    "\n",
    "1. Define the space of hyperparameters to search\n",
    "1. Define the function used to evaluate a given configuration\n",
    "1. Minimize the loss using Space and Function defined in previous steps."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import skopt\n",
    "\n",
    "from feature_selection import FeatureSelection, FeatureEquidistantSelection\n",
    "from sklearn.pipeline import Pipeline\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Integer\n",
    "\n",
    "\n",
    "# pipe = Pipeline([(\"transform\", FeatureEquidistantSelection()), ('svc', SVC())])\n",
    "pipe = Pipeline([(\"transform\", FeatureSelection()), ('svc', SVC())])\n",
    "\n",
    "params = dict()\n",
    "n_features = x.shape[1]\n",
    "# params['transform__n_features_to_select'] = (8, 34, 'uniform')\n",
    "params['transform__selected_features'] = Integer(1, float(2**(116)-1), 'log-uniform')\n",
    "params['svc__C'] = (1e-6, 100.0, 'log-uniform')\n",
    "params['svc__gamma'] = (1e-6, 100.0, 'log-uniform')\n",
    "params['svc__degree'] = (1,5)\n",
    "params['svc__kernel'] = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "\n",
    "# define evaluation\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# define the search\n",
    "search = BayesSearchCV(estimator=pipe, search_spaces=params, n_jobs=-1, cv=cv)\n",
    "# perform the search\n",
    "search.fit(x, y)\n",
    "# report the best result\n",
    "print(search.best_score_)\n",
    "print(search.best_params_)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Ant Colony Optimization (Testing)\n",
    "\n",
    "**Buff, no furula. Buscar otra lib?**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "probar **scikit-opt**: https://github.com/guofei9987/scikit-opt\n",
    "\n",
    "https://www.youtube.com/watch?v=YFN_fJEu63w"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "nodes = []\n",
    "for _ in range(20):\n",
    "  x = np.random.uniform(-10, 10)\n",
    "  y = np.random.uniform(-10, 10)\n",
    "  nodes.append((x, y))\n",
    "\n",
    "nodes"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pants\n",
    "import math\n",
    "\n",
    "def euclidean(a, b):\n",
    "    return math.sqrt(pow(a[1] - b[1], 2) + pow(a[0] - b[0], 2))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "world = pants.World(nodes, euclidean)\n",
    "solver = pants.Solver()\n",
    "# solution = solver.solve(world)\n",
    "\n",
    "solutions = solver.solutions(world)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# print(solution.distance)\n",
    "# print(solution.tour)    # Nodes visited in order\n",
    "# print(len(solution.tour))\n",
    "# print(solution.path)    # Edges taken in order\n",
    "# print(len(solution.path))\n",
    "\n",
    "best = float(\"inf\")\n",
    "for solution in solutions:\n",
    "    assert solution.distance < best\n",
    "    best = solution.distance\n",
    "    print(best)\n",
    "    print(len(solution.path))\n",
    "\n",
    "print(best)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "For each centroid, only the 10 most similar pixels are selected, having a total of 1000 pixels per class (100 centroids Ã—10 pixels). Thus, the reduced dataset is\n",
    "intended to avoid the inclusion of redundant information in the training of the supervised classifier..."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "solver.trace_elite[0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "n_cluster = 2\n",
    "\n",
    "X = np.array([[1, 2.5], [1, 4.1], [1, 0.1],\n",
    "        [10, 2.1], [10, 4.9], [10, 0]])\n",
    "\n",
    "kmeans = KMeans(n_clusters=n_cluster, random_state=0).fit(X)\n",
    "centroid = kmeans.cluster_centers_\n",
    "for x in X:\n",
    "    plt.scatter(x=x[0], y=x[1], alpha=.2)\n",
    "\n",
    "for x in centroid:\n",
    "    plt.scatter(x=x[0], y=x[1], marker='*')\n",
    "\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('HySpecLab': conda)"
  },
  "interpreter": {
   "hash": "af680f298c3d17ec705d00ff05262bced2955ca0c4523d2b3ea9cadbd32c0648"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}